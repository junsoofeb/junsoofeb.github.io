---
bg: "tf.jpg"
layout: post
title:  "2020-01-13_Object_Detection_API_3 내가 가진 데이터로 학습시키기"
crawlertitle: "Tensorflow Object Detection API"
summary: "Object Detection"
date:   2020-01-13
categories: posts
tags: ['Object_Detection']
author: parkjunsoo
---


## Tensorflow Object Detection API (3) 내가 가진 데이터로 학습
***

###### 아래 링크를 참고하여 진행하였습니다.
###### <https://androidkt.com/train-object-detection/>

#### 1. 내가 가진 데이터를 사용해서 Tensorflow Object Detection API를 써보자.

나는 분리수거를 하는 로봇팔 프로젝트를 진행 중이여서,  
크게 비닐, 캔, 페트병 3개를 Detecting하는 모델이 필요했다.  

이번 글에서는 나만의 데이터로 나만의 모델을 학습시키는 법에 대해서 알아본다.   

###### 최종 결과부터 보자면 아래와 같다. (24분간 학습)

![od1](https://github.com/junsoofeb/junsoofeb.github.io/raw/master/assets/images/od1.png)


***

#### 2. Google Cloud에서 프로젝트 설정

###### 이번 글 또한, 구글 클라우드 환경에서 수행한다.

##### Google Cloud에서 프로젝트 설정의 순서는 아래와 같다.

{% highlight js %}  

1. GCP 프로젝트를 만든다.  
<https://cloud.google.com/resource-manager/docs/creating-managing-projects>

2. Google Cloud SDK를 설치한다.  
<https://cloud.google.com/sdk/downloads>

3. GCP 프로젝트에서 ML Engine API를 사용할 수 있도록 설정을 바꾼다.  
<https://console.cloud.google.com/flows/enableapi?apiid=ml.googleapis.com,compute_component&_ga=1.73374291.1570145678.1496689256>

4. GCS(Googlc Cloud Storage) bucket을 만든다.  
<https://cloud.google.com/storage/docs/creating-buckets>

{% endhighlight %}

##### 위 내용은 간단하므로 관련 링크로 대신한다.

***

#### 3. 나만의 데이터를 준비한다.


###### 먼저 *.jpg 형식의 데이터가 필요하다.

icrawl을 사용하여 Google, Bing에서 이미지를 크롤링한 후, imagemagick를 사용해서  
형식과 크기를 통일시켰다.

자세한 사용방법은 아래 포스트를 참고하면 된다.  

<https://junsoofeb.github.io/posts/icrawl-1/>  

<https://junsoofeb.github.io/posts/icrawl-2/>  


이번 글에서 사용한 데이터는 비닐, 캔, 페트병 각각 10장씩, 총 30장이다.  
빠른 학습과 설명을 위해서 간단히 준비했다.  

models/research/images 에 준비한 이미지들을 저장한다.

train_data와 test_data로 이미지들을 9:1 비율로 나누어서,  
models/research/images/train 디렉토리와  models/research/images/test 디렉토리에  
복사해서 저장한다.

최종 모습은 이렇게 되어 있어야 한다.  


![od3_1](https://github.com/junsoofeb/junsoofeb.github.io/raw/master/assets/images/od3_1.png)

![od3_2](https://github.com/junsoofeb/junsoofeb.github.io/raw/master/assets/images/od3_2.png)

![od3_3](https://github.com/junsoofeb/junsoofeb.github.io/raw/master/assets/images/od3_3.png)


###### 이제 labelImg를 이용해서 라벨링 작업을 해야한다.

이 과정은 간단하므로 가볍게 설명.  

models/research/annotations/train_xml 디렉토리에 train_data의 xml을 저장하고,  
models/research/annotations/test_xml 디렉토리에 test_data의 xml을 저장한다.    


최종 모습은 이렇게 되어 있어야 한다.  

![od3_4](https://github.com/junsoofeb/junsoofeb.github.io/raw/master/assets/images/od3_4.png)

![od3_5](https://github.com/junsoofeb/junsoofeb.github.io/raw/master/assets/images/od3_5.png)

![od3_6](https://github.com/junsoofeb/junsoofeb.github.io/raw/master/assets/images/od3_6.png)


###### 기본적인 data의 준비가 끝났다.

***

#### 4. TFRecord형식으로 준비한 data 변환하기.

Tensorflow Object Detection API 에서는 TFRecord형식으로 데이터를 주어야 한다.
먼저 xml을 csv로 바꿔줘야 한다.

아래 코드 xml_to_csv.py를 실행하면 train_labels.csv와 test_labels.csv파일이 생성된다.  

{% highlight js %}  

// models/research 디렉토리에서 수행!

import os
import glob
import pandas as pd
import xml.etree.ElementTree as ET


def xml_to_csv(path):  
    xml_list = []  
    for xml_file in glob.glob(path + '/*.xml'):  
        tree = ET.parse(xml_file)  
        root = tree.getroot()  
        for member in root.findall('object'):  
            value = (root.find('filename').text,  
                     int(root.find('size')[0].text),  
                     int(root.find('size')[1].text),  
                     member[0].text,  
                     int(member[4][0].text),  
                     int(member[4][1].text),  
                     int(member[4][2].text),  
                     int(member[4][3].text)  
                     )  
            xml_list.append(value)  
    column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']  
    xml_df = pd.DataFrame(xml_list, columns=column_name)  
    return xml_df  


def main():  
    directory = ['train', 'test']  
    for d in directory:  
        image_path = os.path.join(os.getcwd(), f'annotations/{d}_xml')  
        xml_df = xml_to_csv(image_path)  
        xml_df.to_csv(f'{d}_labels.csv', index=None)  
        print('Successfully converted xml to csv.')  


main()

{% endhighlight %}

###### 이제 csv파일을 TFRecord로 바꾸자.

아래 코드를 수행하면, train.record 와 test.record가 생성된다.  

{% highlight js %}

"""
usage:
  # From tensorflow/models/research에서 수행  
  # Create train data:  
  python generate_tfrecord.py --csv_input=train_labels.csv  --output_path=train.record  
  # Create test data:  
  python generate_tfrecord.py --csv_input=test_labels.csv  --output_path=test.record  
"""

from __future__ import division  
from __future__ import print_function  
from __future__ import absolute_import  

import os  
import io  
import pandas as pd  
import tensorflow as tf  

from PIL import Image  
from object_detection.utils import dataset_util  
from collections import namedtuple, OrderedDict  

flags = tf.app.flags  
flags.DEFINE_string('csv_input', '', 'Path to the CSV input')  
flags.DEFINE_string('output_path', '', 'Path to output TFRecord')  
flags.DEFINE_string('image_dir', 'images', 'Path to images')  
FLAGS = flags.FLAGS


#TO-DO replace this with label map  
def class_text_to_int(row_label):  
    if row_label == 'VINYL':  
        return 1  
    elif row_label == 'CAN':  
        return 2  
    elif row_label == 'PET':  
        return 3  
    else:  
        return None  

def split(df, group):  
    data = namedtuple('data', ['filename', 'object'])  
    gb = df.groupby(group)  
    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]  


def create_tf_example(group, path):  
    with tf.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:  
        encoded_jpg = fid.read()  
    encoded_jpg_io = io.BytesIO(encoded_jpg)  
    image = Image.open(encoded_jpg_io)  
    width, height = image.size  

    filename = group.filename.encode('utf8')  
    image_format = b'jpg'  
    xmins = []  
    xmaxs = []  
    ymins = []  
    ymaxs = []  
    classes_text = []  
    classes = []  

    for index, row in group.object.iterrows():  
        xmins.append(row['xmin'] / width)  
        xmaxs.append(row['xmax'] / width)  
        ymins.append(row['ymin'] / height)  
        ymaxs.append(row['ymax'] / height)  
        classes_text.append(row['class'].encode('utf8'))  
        classes.append(class_text_to_int(row['class']))  

    tf_example = tf.train.Example(features=tf.train.Features(feature={  
        'image/height': dataset_util.int64_feature(height),  
        'image/width': dataset_util.int64_feature(width),  
        'image/filename': dataset_util.bytes_feature(filename),  
        'image/source_id': dataset_util.bytes_feature(filename),  
        'image/encoded': dataset_util.bytes_feature(encoded_jpg),  
        'image/format': dataset_util.bytes_feature(image_format),  
        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),  
        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),  
        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),  
        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),  
        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),  
        'image/object/class/label': dataset_util.int64_list_feature(classes),  
    }))  
    return tf_example  


def main(_):  
    writer = tf.python_io.TFRecordWriter(FLAGS.output_path)  
    path = os.path.join(FLAGS.image_dir)  
    examples = pd.read_csv(FLAGS.csv_input)  
    grouped = split(examples, 'filename')  
    for group in grouped:  
        tf_example = create_tf_example(group, path)  
        writer.write(tf_example.SerializeToString())  

    writer.close()  
    output_path = os.path.join(os.getcwd(), FLAGS.output_path)  
    print('Successfully created the TFRecords: {}'.format(output_path))  


if __name__ == '__main__':  
    tf.app.run()  

{% endhighlight %}

***

#### 5. label_map.pbtxt 생성 및 pre-trained model 사용하기  

pre-trained model 사용 과정은 아래 링크 참고!  
<https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md>

나는 ssd_mobilenet_v1_coco 모델을 다운받아서 사용했다.  
(ssd_mobilenet_v1_coco_2018_01_28)   
그 후 이름을 ssd_mobilenet_v1_SP로 바꿔서 config를 수정했다.  

num_classes와 버킷 경로를 변경해주면 된다.

![od3_7](https://github.com/junsoofeb/junsoofeb.github.io/raw/master/assets/images/od3_7.png)
![od3_8](https://github.com/junsoofeb/junsoofeb.github.io/raw/master/assets/images/od3_8.png)

label_map.pbtxt 생성도 간단하다.  
아래와 같이 만들어주면 된다.    
주의할 점은 항상 1부터 시작한다는 점이다.   
![od3_9](https://github.com/junsoofeb/junsoofeb.github.io/raw/master/assets/images/od3_9.png)

***

#### 6. 구글 클라우드 저장소에 업로드하기

{% highlight js %}  

// models/research 디렉토리에서 수행!  
// junsoofeb 부분을 각자의 bucket 이름으로 수정!

gsutil cp train.record gs://junsoofeb/data/

gsutil cp test.record gs://junsoofeb/data/

gsutil cp SP_label_map.pbtxt gs://junsoofeb/data/SP_label_map.pbtxt

sed -i "s|PATH_TO_BE_CONFIGURED|"gs://junsoofeb"/data|g" \
    ssd_mobilenet_v1_SP.config

gsutil cp ssd_mobilenet_v1_SP.config \
    gs://junsoofeb/data/ssd_mobilenet_v1_SP.config

{% endhighlight %}

###### gsutil cp ssd_mobilenet_v1_coco_2018_01_28/model.ckpt.* gs://junsoofeb/data/
까먹지말고 다운받은 pre-trained model 압축을 푼 디렉토리에 있는 model.ckpt.* 파일을 모두 올려줘야 한다!  

***

#### 7. Google Cloud Storage Bucket 들어가서 확인하기

지금까지 과정을 잘 수행했다면, GCS Bucket의 구조는 아래와 같을 것이다.

{% highlight js %}  

junsoofeb/  
  + data/  
    - ssd_mobilenet_v1_SP.config
    - model.ckpt.index  
    - model.ckpt.meta  
    - model.ckpt.data-00000-of-00001  
    - SP_label_map.pbtxt  
    - train.record  
    - test.record  


{% endhighlight %}

***

#### 8. Google Cloud ML Engine에서 학습 및 평가 시작하기.

이제 학습을 시작할 차례인데, 시작하기 위해서 2가지 작업이 필요하다.

##### 1. Tensorflow Object Detection 코드를 포장해야 한다.  
##### 2. Google Cloud ML 작업에 대한 클러스터 구성을 작성해야 한다.

먼저, Tensorflow Object Detection 코드를 포장은 아래와 같이 할 수 있다.  

{% highlight js %}  

// models/research 디렉토리에서 수행!  

bash object_detection/dataset_tools/create_pycocotools_package.sh /tmp/pycocotools  
python setup.py sdist  
(cd slim && python setup.py sdist)

{% endhighlight %}

위의 명령을 수행하면,  
python packages dist/object_detection-0.1.tar.gz, slim/dist/slim-0.1.tar.gz, and /tmp/pycocotools/pycocotools-2.0.tar.gz.  
를 생성한다.


그 다음, Cloud ML에서 학습을 진행하기 위해서는, 클러스터 구성을 해야하는데,  
이번에도 object_detection/samples/cloud/cloud.yml을 그대로 사용했다.

###### 이제 학습과 평가를 시작하자, 아래 코드를 수행하면 된다.

{% highlight js %}  

// models/research 디렉토리에서 수행!  
// junsoofeb 부분을 각자의 bucket 이름으로 수정!

gcloud ml-engine jobs submit training `whoami`_object_detection_SP_`date +%m_%d_%Y_%H_%M_%S` \
    --runtime-version 1.12 \
    --job-dir=gs://junsoofeb/model_dir \
    --packages dist/object_detection-0.1.tar.gz,slim/dist/slim-0.1.tar.gz,/tmp/pycocotools/pycocotools-2.0.tar.gz \
    --module-name object_detection.model_main \
    --region us-central1 \
    --config object_detection/samples/cloud/cloud.yml \
    -- \
    --model_dir=gs://junsoofeb/model_dir \
    --pipeline_config_path=gs://junsoofeb/data/ssd_mobilenet_v1_SP.config

{% endhighlight %}

***

#### 9. Tensorboard를 사용해서 모니터링하기.

{% highlight js %}  

// 이 코드는 local에서 처음 딱 한번만 수행하면 된다.
gcloud auth application-default login

tensorboard --logdir=gs://junsoofeb/model_dir

{% endhighlight %}

***

#### 10. 마무리

연습용이기 때문에 아주 적은 데이터와, 짧은 시간만 학습하였다.

###### 최종 결과.

![od1](https://github.com/junsoofeb/junsoofeb.github.io/raw/master/assets/images/od1.png)

![od2](https://github.com/junsoofeb/junsoofeb.github.io/raw/master/assets/images/od2.png)

![od3](https://github.com/junsoofeb/junsoofeb.github.io/raw/master/assets/images/od3.png)

***

#### 11. Exporting the Tensorflow Graph

학습이 다 끝났다면, 학습된 모델을 받아와서 직접 사용해 볼 수 있다.


{% highlight js %}  

#4545 는 나의 체크포인트, 각자의 체크포인트로 바꿀 것!
#체크포인트는 구글 클라우드 버킷에서 확인 가능!
#From tensorflow/models/research/에서 수행

gsutil cp gs://${YOUR_GCS_BUCKET}/model_dir/model.ckpt-4545.* .

python object_detection/export_inference_graph.py \
    --input_type image_tensor \
    --pipeline_config_path ssd_mobilenet_v1_SP.config \
    --trained_checkpoint_prefix model.ckpt-4545 \
    --output_directory SP-graphs

{% endhighlight %}

SP-graphs디렉토리에 결과물이 저장된다.
