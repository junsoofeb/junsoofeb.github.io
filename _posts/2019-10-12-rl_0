---
bg: "deep.jpg"
layout: post
title:  "2019/10/11 강화학습 study"
crawlertitle: "강화학습"
summary: "강화학습"
date:   2019-10-11
categories: posts
tags: 'reinforcement learning'
author: parkjunsoo
---

#### 1.1 머신러닝의 유형(지도학습, 비지도학습, 강화학습) 및 용어 소개

![ml](https://github.com/junsoofeb/junsoofeb.github.io/raw/master/assets/images/ml.png)


머신러닝의 세 가지 유형과 자주 등장하는 용어들을 대한 소개한다.

AI : artificial intelligence 우리 말로 인공지능을 의미한다.
정확한 정의는 연구자마다 다르지만, 사람이 보기에 '지능을 가졌다.'라고 느낄 수 있는 시스템 또는 그러한 시스템을 탑재한 로봇을 가르킨다.

##### 그리고 이 AI를 구현하는 방법 중 하나가 머신러닝이다.

ML : machine learning 머신러닝을 간단히 설명하면,
'시스템에 데이터를 주고 시스템이 파라미터의 값을 스스로 결정하도록 하는 구조'를 의미한다.

ML이 아닌 예를 들자면, 규칙 기반 시스템을 들 수 있다.
if문 등으로 직접 프로그래밍된 구조는 ML이 아니다.

##### Deep learning 딥러닝이란 ML을 구현하는 알고리즘의 일종이다.
ML을 구현하는 알고리즘에는 로지스틱 회귀, 서포트 벡터 머신(SVM), 결정 트리, 랜덤 포레스트, 신경망(neural networks) 등이 있다.

딥러닝은 그 중에서 신경망의 한 종류에 해당한다.

supervised learning 지도 학습이란 데이터에 대한 정답이 주어진 상태에서 시스템을 학습시키는 방법이다.

정답(레이블)이 부여된 데이터가 시스템의 선생님이 된다고 할 수 있다.

예를 들어서 우편번호를 적은 손글씨를 분류하는 시스템을 들 수 있다.
우편번호를 분류하는 시스템은 각 자릿수의 손글씨를 0부터 9까지의 숫자 중 하나로 분류한다.
이 때 0부터 9까지의 숫자가 레이블이 된다.

이 글의 목적은 강화학습이므로 이만 줄이겠다.

unsupervised learning 비지도 학습이란 데이터에 대한 정답이 주어지지 않은 상태에서 시스템을 학습시키는 방법이다.

즉 데이터의 형태로 학습을 진행하는 방법이다. 예를 들면 그룹 나누기(클러스터링)를 들 수 있다.

이 글의 목적은 강화학습이므로 이만 줄이겠다.

reinforcement learning 강화학습은 주로 '시간 변화에 따른 시스템 제어 규칙 구성' 또는 '대전형 게임의 전략 구성' 등에 응용되는 기법이다.


![rl](https://github.com/junsoofeb/junsoofeb.github.io/raw/master/assets/images/ml.png)

강화학습의 쉬운 예로, 처음 자전거를 타는 방법을 배우는 과정을 떠올리면 좋다.
여러 번 넘어지는 시행착오를 거쳐 자전거를 잘 타도록 배우게 되는데, 강화학습 또한 마찬가지로 시행착오를 반복하며 바람직한 제어 규칙을 익히는 기법이다.

정책반복, 가치반복 등 알고리즘의 자세한 접근은 후술한다.

강화학습의 학습데이터에도 정답(레이블)은 없다. 그러나 길잡이가 될 정보가 아예 없는 것은 아니라, '보상'(가치반복 알고리즘에 해당)이라는 신호로 길잡이 역할을 할 수 있다.

##### 왜 지도학습으로는 안되는가?
만약 지도학습으로 로봇의 보행제어를 학습시키려고 한다면
 '다리 관절을 a각도로, b의 속도로 움직여라' 라는 패턴을 아주 많이 만들고,
그 패턴들에 대한 각각의 정답을 붙여놔야만 한다.

하지만 시시각각으로 상황이 변하는 상황에서 모든 경우에 대해 '이럴 때는 이렇게 해라'라는 패턴과 정답을 만들어 둔다는 것은 불가능하기에 지도학습으로는 할 수 없다.

반면에 강화학습에서는 넘어지지 않고 걸어간 거리를 보상으로 제어 시스템을 학습 시키면, 시행착오를 반복하는 과정을 거쳐 점점 더 먼 거리를 이동 할 수 있게 된다.

***

#### 1.2 겅화학습의 역사

강화학습의 역사에 대해 가볍게 소개한다.

강화학습이라는 이름은 스키너(Burrhus F. Skinner)가 '스키너 상자'라 불리는 쥐를 이용한 실험(조작적 조건형성)을 근거로 제안된 이론이다.

그 실험은 뇌의 학습 메커니즘에 대한 것이었다.

쥐가 상자 안에 있다.
쥐가 상자 안의 버튼을 누르면 먹이(보상)가 나오게 되어 있다.
쥐는 처음에 우연히 버튼을 누르고 먹이를 얻지만, 버튼과 먹이의 관계는 알지 못한다.
하지만 이와 같은 경험이 반복되는 과정에서 쥐는 버튼과 먹이의 관계를 학습하고, 버튼을 누르는 동작을 반복하게 된다는 것이다.

특정 동작에 대해 보상을 부여하면 해당 동작이 반복(강화)된다는 실험 결과를 통해서
이 동작학습 메커니즘을 조작적 조건형성(강화)라고 명명했다.

강화학습은 조작적 조건형성의 강화와의 유사점으로 이런 이름이 붙게 됐다.

#### 1.3 강화학습 용어 정리

0. agent 제어대상
시스템에서 제어하고 하는 대상이다.

1. state 상태, s(t)로 표현한다.
어떤 시각 t에서 제어대상이 처한 환경을 재현할 수 있도록 필요한 정보이다.

2. action 행동, a(t)로 표현한다.
어떤 시각의 상태 s(t)에서 제어대상이 취할 수 있는 행동을 의미한다.
선택지라고 생각하면 쉽다

3. policy 정책, π로 표현한다.
제어대상이 어떤 행동을 선택할지 결정하는 규칙이다.
선택지를 선택하는 기준이라고 생각하면 쉽다.
